---
{"dg-publish":true,"permalink":"/10-wiki/12-notes/bias-variance-tradeoff-20230215064841/","tags":["wiki/meta/random"]}
---

# Bias Variance Tradeoff
---
The bias-variance tradeoff is a key concept in [[10 Wiki/13 Plantations/Machine Learning - 20230221102815\|Machine Learning - 20230221102815]] that refers to the tradeoff between a model's ability to fit the training data (i.e., low [[10 Wiki/12 Notes/Datascience Bias - 20230214093010\|Datascience Bias]]) and its ability to generalize to new, unseen data (i.e., low [[100 Zettelkasten/Variance\|Variance]]).

The bias-variance tradeoff arises because reducing bias tends to increase variance, and reducing variance tends to increase bias. The goal is to find the right balance between bias and variance that leads to a model that generalizes well to new data. This can be achieved through various techniques, such as adjusting the model complexity, increasing the amount of training data, or using regularization methods.



###### META
Status:: #wiki/notes/mature 
Plantations:: [[10 Wiki/13 Plantations/Data Science Metrics - 20230221095821\|Data Science Metrics]]
References:: [[10 Wiki/14 References/Books/Mastering Machine Learning with scikit-learn - 20230122071907\|Mastering Machine Learning with scikit-learn]]
